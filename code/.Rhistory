write.csv(ds, "C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data_scaled.csv", row.names=FALSE)
ds = read.csv("C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data.csv")
summary(ds)
str(ds)
# checking for null values
sum(is.na(ds$Engine.rpm))
sum(is.na(ds$Coolant.temp))
sum(is.na(ds$lub.oil.temp))
sum(is.na(ds$Coolant.pressure))
sum(is.na(ds$Fuel.pressure))
sum(is.na(ds$Lub.oil.pressure))
sum(is.na(ds$Engine.Condition))
# Engine RPM analysis
data = ds$Engine.rpm
min(data)
max(data)
mean(data)
library(ggplot2)
ggplot(data=ds, mapping=aes(x=Engine.rpm))+geom_histogram(bins=100)
Q1 = quantile(ds$Engine.rpm, 0.25)
Q3 = quantile(ds$Engine.rpm, 0.75)
print(paste("25th Percentile => ", Q1))
print(paste("75th Percentile => ", Q3))
IQR = Q3 - Q1
print(paste("Inter Quartile Range => ", IQR))
print(paste("Theoritical Min => ", Q1 - 1.7 * IQR))
print(paste("Theoritical Max => ", Q3 + 1.7 * IQR))
nrow(subset(ds, ds$Engine.rpm < Q1 - 1.5 * IQR))
nrow(subset(ds, ds$Engine.rpm > Q3 + 1.5 * IQR))
# important => do not repeat this step again and again, it will try and remove outliers from the data set who already has its outliars removed.
ds = subset(ds, ds$Engine.rpm > Q1 - 1.5 * IQR & ds$Engine.rpm < Q3 + 1.5 * IQR)
ggplot(data=ds, mapping=aes(x=Engine.rpm))+geom_histogram(bins=100)
data = ds$Lub.oil.pressure
min(data)
max(data)
mean(data)
ggplot(data=ds, mapping=aes(x=Lub.oil.pressure))+geom_histogram(bins=100)
mean = mean(ds$Lub.oil.pressure)
std = sd(ds$Lub.oil.pressure)
print(mean)
print(std)
nrow(subset(ds, (ds$Lub.oil.pressure-mean)/std > 3.0))
nrow(subset(ds, (ds$Lub.oil.pressure-mean)/std < -3.0))
print(paste(nrow(ds), " = ", sum((ds$Lub.oil.pressure-mean)/std < -3.0 |  (ds$Lub.oil.pressure-mean)/std > 3.0), " + ", sum((ds$Lub.oil.pressure-mean)/std >= -3.0 &  (ds$Lub.oil.pressure-mean)/std <= 3.0)))
# important => do not repeat this step again and again, it will try and remove outliers from the data set who already has its outliars removed.
ds = subset(ds, (ds$Lub.oil.pressure-mean)/std >= -3.0 &  (ds$Lub.oil.pressure-mean)/std <= 3.0)
ggplot(data=ds, mapping=aes(x=Lub.oil.pressure))+geom_histogram(bins=100)
data = ds$Fuel.pressure
min(data)
max(data)
mean(data)
ggplot(data=ds, mapping=aes(x=Fuel.pressure))+geom_histogram(bins=100)
mean = mean(ds$Fuel.pressure)
std = sd(ds$Fuel.pressure)
print(mean)
print(std)
nrow(subset(ds, (ds$Fuel.pressure-mean)/std > 3.0))
nrow(subset(ds, (ds$Fuel.pressure-mean)/std < -3.0))
print(paste(nrow(ds), " = ", sum((ds$Fuel.pressure-mean)/std < -3.0 |  (ds$Fuel.pressure-mean)/std > 3.0), " + ", sum((ds$Fuel.pressure-mean)/std >= -3.0 &  (ds$Fuel.pressure-mean)/std <= 3.0)))
Q1 = quantile(ds$Fuel.pressure, 0.25)
Q3 = quantile(ds$Fuel.pressure, 0.75)
print(paste("25th Percentile => ", Q1))
print(paste("75th Percentile => ", Q3))
IQR = Q3 - Q1
print(paste("Inter Quartile Range => ", IQR))
print(paste("Theoritical Min => ", Q1 - 1.7 * IQR))
print(paste("Theoritical Max => ", Q3 + 1.7 * IQR))
nrow(subset(ds, ds$Fuel.pressure < Q1 - 1.5 * IQR))
nrow(subset(ds, ds$Fuel.pressure > Q3 + 1.5 * IQR))
# important => do not repeat this step again and again, it will try and remove outliers from the data set who already has its outliars removed.
ds = subset(ds, (ds$Fuel.pressure-mean)/std >= -3.0 &  (ds$Fuel.pressure-mean)/std <= 3.0)
ggplot(data=ds, mapping=aes(x=Fuel.pressure))+geom_histogram(bins=100)
data = ds$Coolant.pressure
min(data)
max(data)
mean(data)
ggplot(data=ds, mapping=aes(x=Coolant.pressure))+geom_histogram(bins=100)
mean = mean(ds$Coolant.pressure)
std = sd(ds$Coolant.pressure)
print(mean)
print(std)
nrow(subset(ds, (ds$Coolant.pressure-mean)/std > 3.0))
nrow(subset(ds, (ds$Coolant.pressure-mean)/std < -3.0))
print(paste(nrow(ds), " = ", sum((ds$Coolant.pressure-mean)/std < -3.0 |  (ds$Coolant.pressure-mean)/std > 3.0), " + ", sum((ds$Coolant.pressure-mean)/std >= -3.0 &  (ds$Coolant.pressure-mean)/std <= 3.0)))
Q1 = quantile(ds$Coolant.pressure, 0.25)
Q3 = quantile(ds$Coolant.pressure, 0.75)
print(paste("25th Percentile => ", Q1))
print(paste("75th Percentile => ", Q3))
IQR = Q3 - Q1
print(paste("Inter Quartile Range => ", IQR))
print(paste("Theoritical Min => ", Q1 - 1.7 * IQR))
print(paste("Theoritical Max => ", Q3 + 1.7 * IQR))
nrow(subset(ds, ds$Coolant.pressure < Q1 - 1.5 * IQR))
nrow(subset(ds, ds$Coolant.pressure > Q3 + 1.5 * IQR))
# important => do not repeat this step again and again, it will try and remove outliers from the data set who already has its outliars removed.
ds = subset(ds, ds$Coolant.pressure > Q1 - 1.5 * IQR & ds$Coolant.pressure < Q3 + 1.5 * IQR)
ggplot(data=ds, mapping=aes(x=Coolant.pressure))+geom_histogram(bins=100)
data = ds$lub.oil.temp
min(data)
max(data)
mean(data)
ggplot(data=ds, mapping=aes(x=lub.oil.temp))+geom_histogram(bins=100)
data = ds$Coolant.temp
min(data)
max(data)
mean(data)
ggplot(data=ds, mapping=aes(x=Coolant.temp))+geom_histogram(bins=100)
mean = mean(ds$Coolant.temp)
std = sd(ds$Coolant.temp)
print(mean)
print(std)
nrow(subset(ds, (ds$Coolant.temp-mean)/std > 3.0))
nrow(subset(ds, (ds$Coolant.temp-mean)/std < -3.0))
print(paste(nrow(ds), " = ", sum((ds$Coolant.temp-mean)/std < -3.0 |  (ds$Coolant.temp-mean)/std > 3.0), " + ", sum((ds$Coolant.temp-mean)/std >= -3.0 &  (ds$Coolant.temp-mean)/std <= 3.0)))
# important => do not repeat this step again and again, it will try and remove outliers from the data set who already has its outliars removed.
ds = subset(ds, (ds$Coolant.temp-mean)/std >= -3.0 &  (ds$Coolant.temp-mean)/std <= 3.0)
ggplot(data=ds, mapping=aes(x=Coolant.temp))+geom_histogram(bins=100)
write.csv(ds, "C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data_removed_missing_and_outliers.csv", row.names=FALSE)
# get the scaled one from file
ds = read.csv("C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data_removed_missing_and_outliers.csv")
ds$Engine.rpm = (ds$Engine.rpm - min(ds$Engine.rpm))/(max(ds$Engine.rpm) - min(ds$Engine.rpm))
ds$Lub.oil.pressure = (ds$Lub.oil.pressure - min(ds$Lub.oil.pressure))/(max(ds$Lub.oil.pressure) - min(ds$Lub.oil.pressure))
ds$Fuel.pressure = (ds$Fuel.pressure - min(ds$Fuel.pressure))/(max(ds$Fuel.pressure) - min(ds$Fuel.pressure))
ds$Coolant.pressure = (ds$Coolant.pressure - min(ds$Coolant.pressure))/(max(ds$Coolant.pressure) - min(ds$Coolant.pressure))
ds$lub.oil.temp = (ds$lub.oil.temp - min(ds$lub.oil.temp))/(max(ds$lub.oil.temp) - min(ds$lub.oil.temp))
ds$Coolant.temp = (ds$Coolant.temp - min(ds$Coolant.temp))/(max(ds$Coolant.temp) - min(ds$Coolant.temp))
print(paste(min(ds$Engine.rpm), max(ds$Engine.rpm)))
print(paste(min(ds$Lub.oil.pressure), max(ds$Lub.oil.pressure)))
print(paste(min(ds$Fuel.pressure), max(ds$Fuel.pressure)))
print(paste(min(ds$Coolant.pressure), max(ds$Coolant.pressure)))
print(paste(min(ds$lub.oil.temp), max(ds$lub.oil.temp)))
print(paste(min(ds$Coolant.temp), max(ds$Coolant.temp)))
write.csv(ds, "C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data_scaled.csv", row.names=FALSE)
# Install and load necessary packages
install.packages("e1071")
library(e1071)
nb_model <- naiveBayes(train_data[, -ncol(train_data)], train_data[, ncol(train_data)])
df <- read.csv("C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/dataset/engine_data_scaled.csv")
str(df)
nrow(subset(df, Engine.Condition == 1))
nrow(subset(df, Engine.Condition == 0))
set.seed(123)
df$Engine.Condition = factor(df$Engine.Condition)
class_counts <- table(df$Engine.Condition)
min_class_count <- min(class_counts)
# Randomly sample from each class to make it equal
balanced_df <- do.call(rbind, lapply(levels(df$Engine.Condition), function(x) {
df_class <- df[df$Engine.Condition == x, ]
return(df_class[sample(nrow(df_class), min_class_count), ])
}))
# Check the structure of the balanced dataset
str(balanced_df)
# test if balanced
table(balanced_df$Engine.Condition)
library(caret)
set.seed(123)
# Create the train-test split indices
train_index <- createDataPartition(balanced_df$Engine.Condition, p = 0.7, list = FALSE)
# Create the training and testing datasets
train_data <- balanced_df[train_index, ]
test_data <- balanced_df[-train_index, ]
# Check the dimensions of the training and testing datasets
dim(train_data)
dim(test_data)
# even the train and test data is class balanced
table(train_data$Engine.Condition)
table(test_data$Engine.Condition)
names(train_data)
# Install and load necessary packages
install.packages("e1071")
library(e1071)
model_NB <- naiveBayes(train_data[, -ncol(train_data)], train_data[, ncol(train_data)])
# Make predictions on test data
predicted_values_NB <- predict(nb_model, test_data[, -ncol(test_data)])
install.packages("e1071")
# Install and load necessary packages
install.packages("e1071")
library(e1071)
model_NB <- naiveBayes(train_data[, -ncol(train_data)], train_data[, ncol(train_data)])
# Make predictions on test data
predicted_values_NB <- predict(model_NB, test_data[, -ncol(test_data)])
# Print predictions
print(predicted_values_NB)
summary(model_NB)
correct <- sum(predicted_values_NB == as.logical(as.integer(test_data$Engine.Condition)-1))
total <- nrow(test_data)
print(c("accuracy = ", correct/total))
correct <- sum(as.logical(as.integer(predicted_values_NB)-1) == as.logical(as.integer(test_data$Engine.Condition)-1))
total <- nrow(test_data)
print(c("accuracy = ", correct/total))
# Install and load necessary packages
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(tree_model, test_data)
# Install and load necessary packages
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(model_DT, test_data)
# Print predictions
print(predicted_values_DT)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
# Install and load necessary packages
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(model_DT, test_data)
install.packages("rpart")
# Install and load necessary packages
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(model_DT, test_data)
# Print predictions
print(which.max(predicted_values_DT[1]))
# Print predictions
for(i in predicted_values_DT) {
print(which.max(predicted_values_DT[i]))
}
# Print predictions
for(i in predicted_values_DT) {
print(predicted_values_DT[i])
}
# Print predictions
for(i in predicted_values_DT) {
print(i)
}
# Print predictions
for(i in nrow(predicted_values_DT)) {
print(i)
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(predicted_values_DT[i])
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(predicted_values_DT[1])
}
# Print predictions
print(predicted_values_DT)
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(predicted_values_DT[1, ])
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[1, ]))
}
# Install and load necessary packages
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(model_DT, test_data)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
library(rpart)
# Assuming train_data has the response variable as the last column
# and test_data is similar without the response variable
# Train decision tree model
model_DT <- rpart(train_data[, ncol(train_data)] ~ ., data = train_data[, -ncol(train_data)])
# Make predictions on test data
predicted_values_DT <- predict(model_DT, test_data)
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(predicted_values_DT[1, ])
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, ]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, 1:2]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print((predicted_values_DT[i, ]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, 1:2]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, 2:3]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, 1:2]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print((predicted_values_DT[i, ]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(max.col(predicted_values_DT[i, ]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(max.col(predicted_values_DT[i, 1]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(max.col(predicted_values_DT[i, 2]))
}
# Print predictions
for(i in 1:nrow(predicted_values_DT)) {
print(max.col(predicted_values_DT[i, ]))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(max.col(predicted_values_DT[i, ]))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(max(predicted_values_DT[i, ]))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(which.max(predicted_values_DT[i, ]))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(which(predicted_values_DT == max(predicted_values_DT[i, ])))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
for (i in 1:nrow(predicted_values_DT)) {
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[nrows(predicted_values)+1] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[nrow(predicted_values)+1] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
table(predicted_values)
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[nrow(predicted_values)] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c(1)
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[nrow(predicted_values)] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[nrow(predicted_values)] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))-1
print(as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))))
}
View(predicted_values_DT)
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
#predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = as.integer(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = which(predicted_values_DT[i] == max(predicted_values_DT[i, ]))
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
# Print predictions
predicted_values = c()
for (i in 1:nrow(predicted_values_DT)) {
predicted_values[i] = 1
print(which(predicted_values_DT[i] == max(predicted_values_DT[i, ])))
}
predicted_classes <- apply(predicted_values_DT, 1, which.max)
predicted_classes <- apply(predicted_values_DT, 1, which.max)
print(predicted_classes)
predicted_classes = predicted_classes-1
print(predicted_classes)
correct <- sum(as.logical(as.integer(predicted_classes)) == as.logical(as.integer(test_data$Engine.Condition)-1))
total <- nrow(test_data)
print(c("accuracy = ", correct/total))
shiny::runApp('C:/Users/nimal/eclipse-workspace/CourseProjects/syCourseProject/DS/code')
